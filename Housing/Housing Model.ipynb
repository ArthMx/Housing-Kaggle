{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble : libraries import, function and class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.special import boxcox1p\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, Imputer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder of categorical (object) features  to dummy features\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class dummy_encoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.cols = X.loc[:, X.dtypes == np.object].columns\n",
    "        self.dummy_cols = pd.get_dummies(X, columns=self.cols).columns\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = pd.get_dummies(X, columns=self.cols)\n",
    "        X_transformed = X_transformed.reindex(columns=self.dummy_cols, fill_value=0)\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select best categorical columns (after transformation in dummy variables) \n",
    "# by choosing columns with lowest p-value from ANOVA test\n",
    "\n",
    "class anova_best_p_selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k_best=None, p_limit=10**(-5)):\n",
    "        self.p_limit = p_limit\n",
    "        self.k_best = k_best\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # select dummy columns\n",
    "        X_cat = X.filter(regex='_')\n",
    "        # append target value to X\n",
    "        df = X_cat.join(y)\n",
    "        # select column name for y value\n",
    "        self.target_col = df.columns[-1]\n",
    "        \n",
    "        # create a dataframe to write F-scores and p-values\n",
    "        self.ANOVA_cat_cols = pd.DataFrame(columns=['F', 'p'])\n",
    "        \n",
    "        for col in X_cat.columns:\n",
    "            pivot_df = df.pivot(columns=col, values=self.target_col)\n",
    "\n",
    "            group_cols = pivot_df.columns\n",
    "            groups = []\n",
    "            for group_col in group_cols:\n",
    "                groups.append(pivot_df[group_col].dropna())\n",
    "\n",
    "            F, p = stats.f_oneway(*groups)\n",
    "            self.ANOVA_cat_cols.loc[col, 'F'] = F\n",
    "            self.ANOVA_cat_cols.loc[col, 'p'] = p\n",
    "        \n",
    "        if self.k_best == None:\n",
    "            # select worst columns of p-value above p_limit\n",
    "            ANOVA_cat_cols_worst = self.ANOVA_cat_cols[ANOVA_cat_cols.p > self.p_limit]\n",
    "            self.worst_cols = ANOVA_cat_cols_worst.index\n",
    "        \n",
    "        else:\n",
    "            # select k_best worst columns of highest p-value\n",
    "            ANOVA_cat_cols_sorted = self.ANOVA_cat_cols.sort_values(by='p')\n",
    "            self.worst_cols = ANOVA_cat_cols_sorted.index[self.k_best:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # drop the worst columns\n",
    "        X_transformed = X.drop(self.worst_cols, axis=1)\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_estimators_gridsearch(preprocess_steps, estimators, params_list, X_train, y_train, X_test, y_test, grid_cv=5):\n",
    "    '''\n",
    "    gridsearch for all estimators given to the function and return different metrics for the training, CV and test set\n",
    "    \n",
    "    preprocess_steps : list of preprocessing steps\n",
    "    estimators : list of estimators who will be append to the pipeline after the preprocessing steps\n",
    "    params_list : list of dictionnary of parameters for the gridsearch \n",
    "    X_train, y_train : for the grid search with Cross validation\n",
    "    X_test, y_test : to test the best model found by gridsearch\n",
    "    \n",
    "    output : dataframe of results, dictionnary of best estimators\n",
    "    '''\n",
    "    \n",
    "    def get_params_grids(estimators, params_list):\n",
    "        '''\n",
    "        input : - estimators : list of estimators \n",
    "                - params_list : list of dictionnary of parameters for gridsearch\n",
    "\n",
    "        ouptut : return a dictionnary of dictionnary of parameters for the gridsearch : estimators -> parameters -> values\n",
    "                ready to be inserted in multi_estimators_gridsearch\n",
    "        '''\n",
    "        params_grids = {}\n",
    "        for estimator, param_grid in zip(estimators, params_list):\n",
    "            estimator_name = estimator.__class__.__name__\n",
    "\n",
    "            params = {}\n",
    "            for key in param_grid:\n",
    "                params[estimator_name.lower() + '__' + key] = param_grid[key]\n",
    "            params_grids[estimator] = params\n",
    "        return params_grids\n",
    "    \n",
    "    params_grids = get_params_grids(estimators, params_list)\n",
    "    \n",
    "    \n",
    "    # set results dataframe\n",
    "    estimators_cols = ['Parameters', 'Train Score Mean', 'CV Score Mean',\n",
    "                       'Test Score Mean', 'CV Score STD' , 'Test RMSE', 'Fitting Time Mean']\n",
    "    estimators_results = pd.DataFrame(columns = estimators_cols)\n",
    "    estimators_results.index.name = 'Estimator Name'\n",
    "    \n",
    "    best_estimators = {}\n",
    "    for estimator in estimators:\n",
    "\n",
    "        #make pipeline : preprocess + estimator\n",
    "        estimator_pipe = make_pipeline(*preprocess_steps, estimator)\n",
    "        \n",
    "        param_grid = params_grids[estimator]\n",
    "\n",
    "        gridsearch = GridSearchCV(estimator_pipe, param_grid=param_grid, cv=grid_cv)\n",
    "        gridsearch.fit(X_train, y_train)\n",
    "        # Cross-validation\n",
    "        cv_results = cross_validate(gridsearch.best_estimator_, X_train, y_train, cv  = 2*grid_cv, return_train_score=True)\n",
    "\n",
    "        #get estimator name\n",
    "        estimator_name = estimator.__class__.__name__\n",
    "        # write estimator parameter\n",
    "        estimators_results.loc[estimator_name, 'Parameters'] = str(gridsearch.best_estimator_.steps[-1][1].get_params())\n",
    "        # write training score mean\n",
    "        estimators_results.loc[estimator_name, 'Train Score Mean'] = cv_results['train_score'].mean()\n",
    "        # write CV score mean\n",
    "        estimators_results.loc[estimator_name, 'CV Score Mean'] = cv_results['test_score'].mean()\n",
    "        # write std of the CV scores\n",
    "        estimators_results.loc[estimator_name, 'CV Score STD'] = cv_results['test_score'].std()\n",
    "\n",
    "        # write test score\n",
    "        estimators_results.loc[estimator_name, 'Test Score Mean'] = gridsearch.score(X_test, y_test)\n",
    "        estimators_results.loc[estimator_name, 'Test RMSE'] = np.sqrt(mean_squared_error(y_test, gridsearch.predict(X_test)))\n",
    "        \n",
    "        # write estimator fit time mean\n",
    "        estimators_results.loc[estimator_name, 'Fitting Time Mean'] = cv_results['fit_time'].mean()\n",
    "        \n",
    "        # append best estimator trained on the whole training set\n",
    "        best_estimators[estimator_name] = gridsearch.best_estimator_\n",
    "        \n",
    "        print(estimator_name, 'DONE')\n",
    "   \n",
    "    return estimators_results, best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig    ...     PoolArea PoolQC Fence  \\\n",
       "Id                                    ...                             \n",
       "1          Lvl    AllPub    Inside    ...            0    NaN   NaN   \n",
       "2          Lvl    AllPub       FR2    ...            0    NaN   NaN   \n",
       "3          Lvl    AllPub    Inside    ...            0    NaN   NaN   \n",
       "4          Lvl    AllPub    Corner    ...            0    NaN   NaN   \n",
       "5          Lvl    AllPub       FR2    ...            0    NaN   NaN   \n",
       "\n",
       "   MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                                         \n",
       "1          NaN       0      2    2008        WD         Normal     208500  \n",
       "2          NaN       0      5    2007        WD         Normal     181500  \n",
       "3          NaN       0      9    2008        WD         Normal     223500  \n",
       "4          NaN       0      2    2006        WD        Abnorml     140000  \n",
       "5          NaN       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset\n",
    "housing = pd.read_csv('data/house-prices-advanced-regression-techniques/train.csv', index_col=0)\n",
    "housing_submission = pd.read_csv('data/house-prices-advanced-regression-techniques/test.csv', index_col=0)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Clean dataset of false nans and outliers\n",
    "Here, I apply different transformation and cleaning function, to both the training and submission set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concat train and test set, to apply same cleaning transformation\n",
    "X_full = pd.concat([housing.drop('SalePrice', axis=1), housing_submission])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eda_num_cols = ['OverallQual','GrLivArea','GarageCars','TotalBsmtSF','FullBath','YearBuilt','BsmtFinSF1','YearRemodAdd', 'MSSubClass']\n",
    "# eda_cat_cols = ['Neighborhood', 'ExterQual', 'BsmtQual', 'KitchenQual', 'GarageFinish']\n",
    "\n",
    "# selected_cols = ['SalePrice'] + eda_num_cols + eda_cat_cols\n",
    "\n",
    "\n",
    "# numerical and categorical columns selected during EDA\n",
    "def column_selector(df, drop_cols=['LotFrontage']):\n",
    "    return df.drop(drop_cols, axis=1)\n",
    "#######################################\n",
    "# Clean dataset of false nans by converting them to categorical value 'None'\n",
    "def false_nan_to_cat(df):\n",
    "    '''\n",
    "    change nan values for the column in the list cols to the value 'None'\n",
    "    '''\n",
    "    cols_nan = df.isnull().sum()\n",
    "    cols_with_nans = cols_nan[cols_nan>0].index\n",
    "    #select false nans columns\n",
    "    false_nan_cols = [col for col in cols_with_nans if col not in ['Electrical']] #['LotFrontage', 'Electrical']\n",
    "    \n",
    "    for col in false_nan_cols:\n",
    "        df.loc[df[col].isnull(), col] = 0\n",
    "    return df\n",
    "#######################################\n",
    "# transform numerical feature to categorical\n",
    "def num_to_cat(df, cols=['MSSubClass']):\n",
    "    for col in cols:\n",
    "        df.loc[:, col] = df[col].astype(np.object)\n",
    "    return df\n",
    "#######################################\n",
    "\n",
    "def normality_transf(df):\n",
    "    \n",
    "    skews = df.select_dtypes(['number']).skew()\n",
    "    skewed_feats = skews[abs(skews) > 0.5]\n",
    "    skewed_features = skewed_feats.index\n",
    "    lam = 0.5\n",
    "    for feat in skewed_features:\n",
    "        df.loc[:, feat] = boxcox1p(df[feat], lam)\n",
    "    return df\n",
    "#######################################\n",
    "# square some features\n",
    "cols_deg2 = ['OverallQual', 'GarageCars', 'YearBuilt', 'YearRemodAdd','FullBath']\n",
    "def deg2_features(df, cols_deg2=cols_deg2):\n",
    "    for col in cols_deg2:\n",
    "        df.loc[:, col+'_sq'] = df[col].pow(2)\n",
    "    return df\n",
    "#######################################\n",
    "# clean dataset of outliers \n",
    "outliers = [524, 1299] # list of outliers Id, other potential outliers : 692, 1183\n",
    "def remove_outliers(df, outliers=outliers):\n",
    "    return df.drop(outliers, axis=0)\n",
    "#######################################\n",
    "\n",
    "# apply all cleaning and feature engeneering to dataframe\n",
    "funcs_list = [column_selector, false_nan_to_cat, remove_outliers, num_to_cat, deg2_features, normality_transf]\n",
    "def apply_cleaning_functions(df, funcs_list=funcs_list):\n",
    "    for func in funcs_list:\n",
    "        df = func(df)\n",
    "    return df\n",
    "\n",
    "housing_clean = apply_cleaning_functions(X_full)\n",
    "y_clean = remove_outliers(housing.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (1458, 234)\n",
      "X nans : 0\n",
      "Series([], dtype: int64)\n",
      "--------------------\n",
      "y nans : 0\n"
     ]
    }
   ],
   "source": [
    "# select predictors and target values and split into train and test set, we drop 'LotFrontage' because there \n",
    "# is too much missing values\n",
    "y = np.log1p(y_clean)\n",
    "X = housing_clean.loc[y.index,:]\n",
    "\n",
    "encoder = dummy_encoder()\n",
    "anova_selector = anova_best_p_selector(k_best=200)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "X_encoded_filtred = anova_selector.fit_transform(X_encoded, y)\n",
    "\n",
    "X = X_encoded_filtred\n",
    "print('X shape :', X_encoded_filtred.shape)\n",
    "\n",
    "\n",
    "# the target values are then transformed to get a distribution closer to the normal distribution (see EDA)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# check nans values\n",
    "X_nans = X.isnull().sum().sort_values(ascending=False)\n",
    "print('X nans :', X.isnull().sum().sum())\n",
    "print(X_nans[X_nans!=0])\n",
    "print('-'*20)\n",
    "print('y nans :', y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. In the search of the best model : Multiple Estimators gridsearch and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using EDA selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor DONE\n",
      "LinearRegression DONE\n",
      "Ridge DONE\n",
      "Lasso DONE\n",
      "RandomForestRegressor DONE\n",
      "GradientBoostingRegressor DONE\n",
      "XGBRegressor DONE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Score Mean</th>\n",
       "      <th>CV Score Mean</th>\n",
       "      <th>Test Score Mean</th>\n",
       "      <th>CV Score STD</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Fitting Time Mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.841654</td>\n",
       "      <td>0.776583</td>\n",
       "      <td>0.751398</td>\n",
       "      <td>0.0466312</td>\n",
       "      <td>0.197621</td>\n",
       "      <td>0.0156105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.952677</td>\n",
       "      <td>-3.68531e+23</td>\n",
       "      <td>-5.65336e+18</td>\n",
       "      <td>1.07633e+24</td>\n",
       "      <td>9.424e+08</td>\n",
       "      <td>0.027268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>{'alpha': 215.44346900318823, 'copy_X': True, ...</td>\n",
       "      <td>0.945453</td>\n",
       "      <td>0.913393</td>\n",
       "      <td>0.911587</td>\n",
       "      <td>0.0242335</td>\n",
       "      <td>0.117853</td>\n",
       "      <td>0.0168613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>{'alpha': 0.0046415888336127772, 'copy_X': Tru...</td>\n",
       "      <td>0.939364</td>\n",
       "      <td>0.915818</td>\n",
       "      <td>0.925082</td>\n",
       "      <td>0.0273223</td>\n",
       "      <td>0.108486</td>\n",
       "      <td>0.10462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>{'bootstrap': True, 'criterion': 'mse', 'max_d...</td>\n",
       "      <td>0.982183</td>\n",
       "      <td>0.871279</td>\n",
       "      <td>0.877723</td>\n",
       "      <td>0.0275248</td>\n",
       "      <td>0.138597</td>\n",
       "      <td>1.46543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>{'alpha': 0.9, 'criterion': 'friedman_mse', 'i...</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.91845</td>\n",
       "      <td>0.0210356</td>\n",
       "      <td>0.113186</td>\n",
       "      <td>0.726485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
       "      <td>0.956047</td>\n",
       "      <td>0.900483</td>\n",
       "      <td>0.911086</td>\n",
       "      <td>0.0247103</td>\n",
       "      <td>0.118186</td>\n",
       "      <td>0.579106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Parameters  \\\n",
       "Estimator Name                                                                 \n",
       "KNeighborsRegressor        {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "LinearRegression           {'copy_X': True, 'fit_intercept': True, 'n_job...   \n",
       "Ridge                      {'alpha': 215.44346900318823, 'copy_X': True, ...   \n",
       "Lasso                      {'alpha': 0.0046415888336127772, 'copy_X': Tru...   \n",
       "RandomForestRegressor      {'bootstrap': True, 'criterion': 'mse', 'max_d...   \n",
       "GradientBoostingRegressor  {'alpha': 0.9, 'criterion': 'friedman_mse', 'i...   \n",
       "XGBRegressor               {'base_score': 0.5, 'booster': 'gbtree', 'cols...   \n",
       "\n",
       "                          Train Score Mean CV Score Mean Test Score Mean  \\\n",
       "Estimator Name                                                             \n",
       "KNeighborsRegressor               0.841654      0.776583        0.751398   \n",
       "LinearRegression                  0.952677  -3.68531e+23    -5.65336e+18   \n",
       "Ridge                             0.945453      0.913393        0.911587   \n",
       "Lasso                             0.939364      0.915818        0.925082   \n",
       "RandomForestRegressor             0.982183      0.871279        0.877723   \n",
       "GradientBoostingRegressor         0.982222      0.898475         0.91845   \n",
       "XGBRegressor                      0.956047      0.900483        0.911086   \n",
       "\n",
       "                          CV Score STD  Test RMSE Fitting Time Mean  \n",
       "Estimator Name                                                       \n",
       "KNeighborsRegressor          0.0466312   0.197621         0.0156105  \n",
       "LinearRegression           1.07633e+24  9.424e+08          0.027268  \n",
       "Ridge                        0.0242335   0.117853         0.0168613  \n",
       "Lasso                        0.0273223   0.108486           0.10462  \n",
       "RandomForestRegressor        0.0275248   0.138597           1.46543  \n",
       "GradientBoostingRegressor    0.0210356   0.113186          0.726485  \n",
       "XGBRegressor                 0.0247103   0.118186          0.579106  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# list of pre-processing steps\n",
    "preprocess_steps = [Imputer(strategy='mean'), StandardScaler()]\n",
    "\n",
    "# estimators to be used\n",
    "kneigh = KNeighborsRegressor()\n",
    "lin_reg = LinearRegression()\n",
    "ridge_reg = Ridge()\n",
    "lasso_reg = Lasso()\n",
    "forest_reg = RandomForestRegressor()\n",
    "gboost_reg = GradientBoostingRegressor()\n",
    "xgb_reg = XGBRegressor()\n",
    "\n",
    "\n",
    "#list of estimators\n",
    "estimators = [\n",
    "        kneigh,\n",
    "        lin_reg,\n",
    "        ridge_reg,\n",
    "        lasso_reg,\n",
    "        forest_reg,\n",
    "        gboost_reg,\n",
    "        xgb_reg,\n",
    "         ]\n",
    "\n",
    "# setting parameters for gridsearch\n",
    "param_kneigh = {'n_neighbors':list(range(3,31,3))}\n",
    "param_lin_reg = {}\n",
    "param_ridge_reg = {'max_iter':[5000], 'alpha':np.logspace(0,3,10)}\n",
    "param_lasso_reg = {'alpha':np.logspace(-5,1,10)}\n",
    "param_forest_reg = {'n_estimators':[10,50,100]}\n",
    "param_gboost_reg = {'n_estimators':[100,200], 'learning_rate':[0.01,0.1,1], 'loss':['ls', 'huber']}\n",
    "param_xgb_reg = {'max_depth':[2,3,4], 'learning_rate':[0.01,0.1,0.5], 'n_estimators':[100,200]}\n",
    "\n",
    "# list of parameters for each estimators\n",
    "params_list = [param_kneigh, param_lin_reg, param_ridge_reg, param_lasso_reg, param_forest_reg, param_gboost_reg, param_xgb_reg]\n",
    "\n",
    "# get results of best estimators found by gridsearch\n",
    "estimators_results, best_models = multi_estimators_gridsearch(preprocess_steps, estimators, params_list, X_train, y_train, X_test, y_test)\n",
    "estimators_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature importance for the best model (Lasso)\n",
    "\n",
    "Using Lasso, we can evaluate the importance of the different features by looking at their associated coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHVCAYAAADhOb+sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3b7479e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select Lasso pipeline\n",
    "best_lasso_pipe = best_models['Lasso']\n",
    "# select the Lasso model\n",
    "best_lasso = best_lasso_pipe.steps[-1][-1]\n",
    "# select the coef of the Lasso model\n",
    "lasso_coef = best_lasso.coef_\n",
    "\n",
    "coef_df = pd.DataFrame({'Lasso Coef':lasso_coef}, index=X.columns)\n",
    "\n",
    "coef_df['abs_coef'] = coef_df['Lasso Coef'].abs()\n",
    "#select the 20 feature of highest absolute coefficient value\n",
    "important_coef = coef_df.sort_values(by='abs_coef', ascending=False).head(20)\n",
    "important_coef_sorted = important_coef.sort_values(by='Lasso Coef', ascending=False)\n",
    "important_coef_sorted['Lasso Coef'].plot(kind='barh', figsize=(8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso has also a special behavior comparted to other linear model. The L1 regularization imposed by Lasso has the property of shrinking the coefficient of lesser importance to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features with coef = 0 : 153\n",
      "ex : \n",
      "Index(['MasVnrArea', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'BsmtHalfBath', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd',\n",
      "       'EnclosedPorch',\n",
      "       ...\n",
      "       'PoolQC_Ex', 'Fence_0', 'Fence_MnPrv', 'Fence_MnWw', 'MiscFeature_0',\n",
      "       'MiscFeature_Shed', 'SaleType_COD', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Normal', 'SaleCondition_Partial'],\n",
      "      dtype='object', length=153)\n"
     ]
    }
   ],
   "source": [
    "coef_zero = coef_df[coef_df['Lasso Coef']==0]\n",
    "print('# features with coef = 0 :', len(coef_zero))\n",
    "print('ex : ')\n",
    "print(coef_zero.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Submission\n",
    "\n",
    "I select the best model, retrain it on the whole dataset, predict and prepare submission file for the Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=0.0046415888336127772, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_name = estimators_results['Test Score Mean'].idxmax()\n",
    "best_model = best_models[best_model_name]\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction for competition set\n",
    "X_submission = housing_clean.loc[housing_submission.index,:]\n",
    "\n",
    "X_submission_encoded = encoder.transform(X_submission)\n",
    "X_submission_transformed = anova_selector.transform(X_submission_encoded)\n",
    "\n",
    "y_submission_pred = best_model.predict(X_submission_transformed)\n",
    "\n",
    "y_comp_pred_final = np.exp(y_submission_pred) - 1\n",
    "df_submission = pd.DataFrame({'SalePrice':y_comp_pred_final}, index=housing_submission.index)\n",
    "df_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
